{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import string\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directory Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = r'D:\\ML Projects\\intent\\\\'\n",
    "data_dir = main_dir + 'classified_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(data_dir, encoding='ISO-8859-1', names = ['statement','intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Need help pleese</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Need help</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I need some info</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Will you help me?</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What else can you do?</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               statement          intent\n",
       "0       Need help pleese  commonQ.assist\n",
       "1              Need help  commonQ.assist\n",
       "2       I need some info  commonQ.assist\n",
       "3      Will you help me?  commonQ.assist\n",
       "4  What else can you do?  commonQ.assist"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of new_data_df containing hindi statements and their corresponding intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(main_dir+'modified_data.csv',encoding='ISO-8859-1')\n",
    "new_data_df = pd.DataFrame(columns = ['statement','intent'])\n",
    "new_data_df['statement'] = data['Hinglish']\n",
    "new_data_df['intent'] = data_df['intent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plaiaisai madad kee zaroorat hai</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>madad chaahie</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mujhe kuchh jaanakaaree chaahie</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kya tum meree madad karoge?</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aap aur kya kar sakate hain?</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          statement          intent\n",
       "0  plaiaisai madad kee zaroorat hai  commonQ.assist\n",
       "1                     madad chaahie  commonQ.assist\n",
       "2   mujhe kuchh jaanakaaree chaahie  commonQ.assist\n",
       "3       kya tum meree madad karoge?  commonQ.assist\n",
       "4      aap aur kya kar sakate hain?  commonQ.assist"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "faq.application_process       203\n",
       "contact.contact               136\n",
       "faq.borrow_use                103\n",
       "faq.biz_simpler                94\n",
       "faq.borrow_limit               76\n",
       "faq.biz_new                    68\n",
       "faq.apply_register             62\n",
       "faq.approval_time              62\n",
       "faq.address_proof              59\n",
       "faq.banking_option_missing     54\n",
       "faq.biz_category_missing       40\n",
       "faq.aadhaar_missing            35\n",
       "commonQ.bot                    26\n",
       "commonQ.assist                 20\n",
       "commonQ.name                   18\n",
       "faq.bad_service                14\n",
       "commonQ.how                    12\n",
       "commonQ.not_giving             11\n",
       "commonQ.wait                    7\n",
       "commonQ.query                   7\n",
       "commonQ.just_details            6\n",
       "Name: intent, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['intent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1113 entries, 0 to 1112\n",
      "Data columns (total 2 columns):\n",
      "statement    1113 non-null object\n",
      "intent       1113 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 17.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1107</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>How do I apply?</td>\n",
       "      <td>faq.application_process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              statement                   intent\n",
       "count              1113                     1113\n",
       "unique             1107                       21\n",
       "top     How do I apply?  faq.application_process\n",
       "freq                  2                      203"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "statement    0\n",
       "intent       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_punc(row):\n",
    "    no_punc = [elem for elem in row if elem not in string.punctuation]\n",
    "    row = ''.join(no_punc)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['statement'] = data_df['statement'].apply(rem_punc)\n",
    "new_data_df['statement'] = new_data_df['statement'].apply(rem_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Need help pleese</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Need help</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I need some info</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Will you help me</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What else can you do</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              statement          intent\n",
       "0      Need help pleese  commonQ.assist\n",
       "1             Need help  commonQ.assist\n",
       "2      I need some info  commonQ.assist\n",
       "3      Will you help me  commonQ.assist\n",
       "4  What else can you do  commonQ.assist"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hharshit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['statement'] = data_df['statement'].apply(lambda col: word_tokenize(col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I would advise against removal of stopwords as it substantially affects the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df['statement'] = data_df['statement'].apply(lambda col: [word for word in col if word.lower() not in Stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Need, help, pleese]</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Need, help]</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[I, need, some, info]</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Will, you, help, me]</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[What, else, can, you, do]</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    statement          intent\n",
       "0        [Need, help, pleese]  commonQ.assist\n",
       "1                [Need, help]  commonQ.assist\n",
       "2       [I, need, some, info]  commonQ.assist\n",
       "3       [Will, you, help, me]  commonQ.assist\n",
       "4  [What, else, can, you, do]  commonQ.assist"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['statement'] = data_df['statement'].apply(lambda row: [word.lower() for word in row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "data_df['statement'] = data_df['statement'].apply(lambda row:[lemmatizer.lemmatize(word) for word in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[need, help, pleese]</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[need, help]</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[i, need, some, info]</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[will, you, help, me]</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[what, else, can, you, do]</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    statement          intent\n",
       "0        [need, help, pleese]  commonQ.assist\n",
       "1                [need, help]  commonQ.assist\n",
       "2       [i, need, some, info]  commonQ.assist\n",
       "3       [will, you, help, me]  commonQ.assist\n",
       "4  [what, else, can, you, do]  commonQ.assist"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmer = PorterStemmer()\n",
    "data_df['statement'] = data_df['statement'].apply(lambda row:[porter_stemmer.stem(word) for word in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[need, help, plees]</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[need, help]</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[i, need, some, info]</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[will, you, help, me]</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[what, els, can, you, do]</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   statement          intent\n",
       "0        [need, help, plees]  commonQ.assist\n",
       "1               [need, help]  commonQ.assist\n",
       "2      [i, need, some, info]  commonQ.assist\n",
       "3      [will, you, help, me]  commonQ.assist\n",
       "4  [what, els, can, you, do]  commonQ.assist"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spell Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['statement'] = data_df['statement'].apply(lambda row:[str(TextBlob(word).correct()) for word in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['statement'] = data_df['statement'].apply(lambda row: \" \".join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>need help pleas</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>need help</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i need some into</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>will you help me</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what else can you do</td>\n",
       "      <td>commonQ.assist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              statement          intent\n",
       "0       need help pleas  commonQ.assist\n",
       "1             need help  commonQ.assist\n",
       "2      i need some into  commonQ.assist\n",
       "3      will you help me  commonQ.assist\n",
       "4  what else can you do  commonQ.assist"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation of the data frames with english and hindi dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenation was performed after spell check because spell check will alter the entire hindi words in dataframe\n",
    "data_df = pd.concat([data_df,new_data_df],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "In this step raw text data will be transferred into feature vectors. I have implemented the following different methods in order to obtain relevant features from the dataset.\n",
    "\n",
    "1. Count Vectors as features\n",
    "2. TF-IDF as features<br>\n",
    "    -> Word level <br>\n",
    "    -> n-gram level <br>\n",
    "    -> character level<br>\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [row[1] for row in data_df['statement'].iteritems()]\n",
    "\n",
    "vect = CountVectorizer()\n",
    "X = vect.fit_transform(corpus)\n",
    "\n",
    "names = vect.get_feature_names()\n",
    "vect_df = pd.DataFrame(X.todense(),columns = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>99</th>\n",
       "      <th>999</th>\n",
       "      <th>999999999</th>\n",
       "      <th>9999999999</th>\n",
       "      <th>aadhaar</th>\n",
       "      <th>aadhaarit</th>\n",
       "      <th>aaeedee</th>\n",
       "      <th>aage</th>\n",
       "      <th>aana</th>\n",
       "      <th>aane</th>\n",
       "      <th>...</th>\n",
       "      <th>ya</th>\n",
       "      <th>yadi</th>\n",
       "      <th>yah</th>\n",
       "      <th>yahaan</th>\n",
       "      <th>ye</th>\n",
       "      <th>year</th>\n",
       "      <th>yojana</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>zaroorat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 946 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   99  999  999999999  9999999999  aadhaar  aadhaarit  aaeedee  aage  aana  \\\n",
       "0   0    0          0           0        0          0        0     0     0   \n",
       "1   0    0          0           0        0          0        0     0     0   \n",
       "2   0    0          0           0        0          0        0     0     0   \n",
       "3   0    0          0           0        0          0        0     0     0   \n",
       "4   0    0          0           0        0          0        0     0     0   \n",
       "\n",
       "   aane    ...     ya  yadi  yah  yahaan  ye  year  yojana  you  your  \\\n",
       "0     0    ...      0     0    0       0   0     0       0    0     0   \n",
       "1     0    ...      0     0    0       0   0     0       0    0     0   \n",
       "2     0    ...      0     0    0       0   0     0       0    0     0   \n",
       "3     0    ...      0     0    0       0   0     0       0    1     0   \n",
       "4     0    ...      0     0    0       0   0     0       0    1     0   \n",
       "\n",
       "   zaroorat  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 946 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aadhaar</th>\n",
       "      <th>aadhaarit</th>\n",
       "      <th>aaeedee</th>\n",
       "      <th>aage</th>\n",
       "      <th>aana</th>\n",
       "      <th>aane</th>\n",
       "      <th>aap</th>\n",
       "      <th>aapaka</th>\n",
       "      <th>aapake</th>\n",
       "      <th>aapakee</th>\n",
       "      <th>...</th>\n",
       "      <th>ya</th>\n",
       "      <th>yadi</th>\n",
       "      <th>yah</th>\n",
       "      <th>yahaan</th>\n",
       "      <th>ye</th>\n",
       "      <th>year</th>\n",
       "      <th>yojana</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>zaroorat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 942 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aadhaar  aadhaarit  aaeedee  aage  aana  aane  aap  aapaka  aapake  \\\n",
       "0        0          0        0     0     0     0    0       0       0   \n",
       "1        0          0        0     0     0     0    0       0       0   \n",
       "2        0          0        0     0     0     0    0       0       0   \n",
       "3        0          0        0     0     0     0    0       0       0   \n",
       "4        0          0        0     0     0     0    0       0       0   \n",
       "\n",
       "   aapakee    ...     ya  yadi  yah  yahaan  ye  year  yojana  you  your  \\\n",
       "0        0    ...      0     0    0       0   0     0       0    0     0   \n",
       "1        0    ...      0     0    0       0   0     0       0    0     0   \n",
       "2        0    ...      0     0    0       0   0     0       0    0     0   \n",
       "3        0    ...      0     0    0       0   0     0       0    1     0   \n",
       "4        0    ...      0     0    0       0   0     0       0    1     0   \n",
       "\n",
       "   zaroorat  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 942 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropped columns with numerical values as they seemed pretty irrelevant\n",
    "vect_df.drop(['99','999','999999999','9999999999'],axis=1,inplace=True)\n",
    "vect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Feature vector\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2226, 945)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['statement'] = data_df['statement'].apply(rem_punc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectors as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word level tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [row[1] for row in data_df['statement'].iteritems()]\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vect.fit_transform(corpus)\n",
    "\n",
    "names = tfidf_vect.get_feature_names()\n",
    "print(X_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aadhaar</th>\n",
       "      <th>aadhaarit</th>\n",
       "      <th>aaeedee</th>\n",
       "      <th>aage</th>\n",
       "      <th>aana</th>\n",
       "      <th>aane</th>\n",
       "      <th>aap</th>\n",
       "      <th>aapaka</th>\n",
       "      <th>aapake</th>\n",
       "      <th>aapakee</th>\n",
       "      <th>...</th>\n",
       "      <th>ya</th>\n",
       "      <th>yadi</th>\n",
       "      <th>yah</th>\n",
       "      <th>yahaan</th>\n",
       "      <th>ye</th>\n",
       "      <th>year</th>\n",
       "      <th>yojana</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>zaroorat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.403180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.354305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 942 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aadhaar  aadhaarit  aaeedee  aage  aana  aane  aap  aapaka  aapake  \\\n",
       "0      0.0        0.0      0.0   0.0   0.0   0.0  0.0     0.0     0.0   \n",
       "1      0.0        0.0      0.0   0.0   0.0   0.0  0.0     0.0     0.0   \n",
       "2      0.0        0.0      0.0   0.0   0.0   0.0  0.0     0.0     0.0   \n",
       "3      0.0        0.0      0.0   0.0   0.0   0.0  0.0     0.0     0.0   \n",
       "4      0.0        0.0      0.0   0.0   0.0   0.0  0.0     0.0     0.0   \n",
       "\n",
       "   aapakee    ...      ya  yadi  yah  yahaan   ye  year  yojana       you  \\\n",
       "0      0.0    ...     0.0   0.0  0.0     0.0  0.0   0.0     0.0  0.000000   \n",
       "1      0.0    ...     0.0   0.0  0.0     0.0  0.0   0.0     0.0  0.000000   \n",
       "2      0.0    ...     0.0   0.0  0.0     0.0  0.0   0.0     0.0  0.000000   \n",
       "3      0.0    ...     0.0   0.0  0.0     0.0  0.0   0.0     0.0  0.403180   \n",
       "4      0.0    ...     0.0   0.0  0.0     0.0  0.0   0.0     0.0  0.354305   \n",
       "\n",
       "   your  zaroorat  \n",
       "0   0.0       0.0  \n",
       "1   0.0       0.0  \n",
       "2   0.0       0.0  \n",
       "3   0.0       0.0  \n",
       "4   0.0       0.0  \n",
       "\n",
       "[5 rows x 942 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect_df = pd.DataFrame(X_tfidf.todense(),columns = names)\n",
    "tfidf_vect_df.drop(['99','999','999999999','9999999999'],axis=1,inplace=True)\n",
    "tfidf_vect_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram level tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect_ngram = TfidfVectorizer(ngram_range=(2,2))\n",
    "X_tfidf_ngram = tfidf_vect_ngram.fit_transform(corpus)\n",
    "\n",
    "names = tfidf_vect_ngram.get_feature_names()\n",
    "print(X_tfidf_ngram.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>99 99</th>\n",
       "      <th>99 999</th>\n",
       "      <th>99 par</th>\n",
       "      <th>999 ab</th>\n",
       "      <th>999999999 call</th>\n",
       "      <th>9999999999 now</th>\n",
       "      <th>aadhaar can</th>\n",
       "      <th>aadhaar card</th>\n",
       "      <th>aadhaar get</th>\n",
       "      <th>aadhaar here</th>\n",
       "      <th>...</th>\n",
       "      <th>your number</th>\n",
       "      <th>your office</th>\n",
       "      <th>your process</th>\n",
       "      <th>your self</th>\n",
       "      <th>your side</th>\n",
       "      <th>your simplerloan</th>\n",
       "      <th>your team</th>\n",
       "      <th>your toll</th>\n",
       "      <th>your toller</th>\n",
       "      <th>zaroorat hai</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3958 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   99 99  99 999  99 par  999 ab  999999999 call  9999999999 now  aadhaar can  \\\n",
       "0    0.0     0.0     0.0     0.0             0.0             0.0          0.0   \n",
       "1    0.0     0.0     0.0     0.0             0.0             0.0          0.0   \n",
       "2    0.0     0.0     0.0     0.0             0.0             0.0          0.0   \n",
       "3    0.0     0.0     0.0     0.0             0.0             0.0          0.0   \n",
       "4    0.0     0.0     0.0     0.0             0.0             0.0          0.0   \n",
       "\n",
       "   aadhaar card  aadhaar get  aadhaar here      ...       your number  \\\n",
       "0           0.0          0.0           0.0      ...               0.0   \n",
       "1           0.0          0.0           0.0      ...               0.0   \n",
       "2           0.0          0.0           0.0      ...               0.0   \n",
       "3           0.0          0.0           0.0      ...               0.0   \n",
       "4           0.0          0.0           0.0      ...               0.0   \n",
       "\n",
       "   your office  your process  your self  your side  your simplerloan  \\\n",
       "0          0.0           0.0        0.0        0.0               0.0   \n",
       "1          0.0           0.0        0.0        0.0               0.0   \n",
       "2          0.0           0.0        0.0        0.0               0.0   \n",
       "3          0.0           0.0        0.0        0.0               0.0   \n",
       "4          0.0           0.0        0.0        0.0               0.0   \n",
       "\n",
       "   your team  your toll  your toller  zaroorat hai  \n",
       "0        0.0        0.0          0.0           0.0  \n",
       "1        0.0        0.0          0.0           0.0  \n",
       "2        0.0        0.0          0.0           0.0  \n",
       "3        0.0        0.0          0.0           0.0  \n",
       "4        0.0        0.0          0.0           0.0  \n",
       "\n",
       "[5 rows x 3958 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect_ngram_df = pd.DataFrame(X_tfidf_ngram.todense(), columns=names)\n",
    "#tfidf_vect_ngram_df.drop(['999999999 call'], axis=1,inplace=True)\n",
    "tfidf_vect_ngram_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character level tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', ngram_range=(2,3))\n",
    "X_tfidf_vect_ngram_chars = tfidf_vect_ngram_chars.fit_transform(corpus)\n",
    "\n",
    "names = tfidf_vect_ngram_chars.get_feature_names()\n",
    "print(X_tfidf_vect_ngram_chars.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>a</th>\n",
       "      <th>aa</th>\n",
       "      <th>ab</th>\n",
       "      <th>ac</th>\n",
       "      <th>ad</th>\n",
       "      <th>af</th>\n",
       "      <th>ag</th>\n",
       "      <th>ai</th>\n",
       "      <th>al</th>\n",
       "      <th>...</th>\n",
       "      <th>y</th>\n",
       "      <th>yo</th>\n",
       "      <th>z</th>\n",
       "      <th>z k</th>\n",
       "      <th>z p</th>\n",
       "      <th>z s</th>\n",
       "      <th>za</th>\n",
       "      <th>zar</th>\n",
       "      <th>o</th>\n",
       "      <th>of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2437 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     a   a    aa   ab   ac   ad   af   ag   ai   al ...    y  yo   z   z k  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "\n",
       "   z p  z s   za  zar   o  of  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 2437 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect_chars_df = pd.DataFrame(X_tfidf_vect_ngram_chars.todense(),columns=names)\n",
    "tfidf_vect_chars_df.drop([' 1', ' 1 ', ' 2', ' 2 ', ' 9', ' 99'],axis=1,inplace=True)\n",
    "tfidf_vect_chars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([' a', ' a ', ' aa', ' ab', ' ac', ' ad', ' af', ' ag', ' ai', ' al',\n",
       "       ...\n",
       "       'y', 'yo', 'z ', 'z k', 'z p', 'z s', 'za', 'zar', 'o', 'of'],\n",
       "      dtype='object', length=2437)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect_chars_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "In this step I have trained classifiers based on the features created in previous step. There are many choices of machine learning models that can be implemented. I have implemented the following models: <br>\n",
    "1. Naive Bayes Classifier\n",
    "2. Logistic Regression\n",
    "3. Random Forest Classifier\n",
    "4. XGBoost Gradient Classifier\n",
    "5. Support Vector Machines(SVM)\n",
    "6. Neural Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier,X_train,y_train,X_test,y_test):\n",
    "    \n",
    "    classifier.fit(X_train,y_train)\n",
    "    predictions = classifier.predict(X_test)\n",
    "    return accuracy_score(predictions,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "lbl_enc = LabelEncoder()\n",
    "\n",
    "\n",
    "vect_df['intent'] = data_df.apply(lbl_enc.fit_transform).iloc[:,-1]\n",
    "\n",
    "tfidf_vect_df['intent'] = data_df.apply(lbl_enc.fit_transform).iloc[:,-1]\n",
    "\n",
    "tfidf_vect_ngram_df['intent'] = data_df.apply(lbl_enc.fit_transform).iloc[:,-1]\n",
    "\n",
    "tfidf_vect_chars_df['intent'] = data_df.apply(lbl_enc.fit_transform).iloc[:,-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train_Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(X_feature,y_feature):\n",
    "    X = X_feature\n",
    "    y = y_feature\n",
    "    \n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.25, random_state=94)\n",
    "    \n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier function dictionary\n",
    "classifier_dict = {'NaiveBayes':GaussianNB(),'LogisticRegression':LogisticRegression(),'RandomForest':RandomForestClassifier(),\n",
    "                  'SVM':svm.LinearSVC(),'xgb':XGBClassifier(max_depth=6,learning_rate=0.15)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes model name as input and trains the model on different types of feature vectors including Count Vectors,\n",
    "# word level tf-idf vectors, ngram level tf-idf vectors and character level tf-idf vectors\n",
    "def classifier(model):\n",
    "    Classifier = classifier_dict[model]\n",
    "\n",
    "    # Classifier on Count Vectors\n",
    "    X = vect_df.iloc[:,:-1]\n",
    "    y = vect_df['intent']\n",
    "    X_train,X_test,y_train,y_test = split_data(X,y)\n",
    "\n",
    "    # List for storing accuracy values\n",
    "    Accuracy = []\n",
    "\n",
    "    accuracy = train_model(Classifier,X_train,y_train,X_test,y_test)\n",
    "    Accuracy.append(accuracy)\n",
    "    print(model,\", Count Vectors: \",accuracy)\n",
    "\n",
    "    # Classifier on Word level TF-IDF vectors\n",
    "    X = tfidf_vect_df.iloc[:,:-1]\n",
    "    y = tfidf_vect_df['intent']\n",
    "    X_train,X_test,y_train,y_test = split_data(X,y)\n",
    "\n",
    "    accuracy = train_model(Classifier,X_train,y_train,X_test,y_test)\n",
    "    Accuracy.append(accuracy)\n",
    "    print(model,\", Word level TF-IDF Vectors: \",accuracy)\n",
    "\n",
    "    # Classifier on N-gram level TF-IDF vectors\n",
    "    X = tfidf_vect_ngram_df.iloc[:,:-1]\n",
    "    y = tfidf_vect_ngram_df['intent']\n",
    "    X_train,X_test,y_train,y_test = split_data(X,y)\n",
    "\n",
    "    accuracy = train_model(Classifier,X_train,y_train,X_test,y_test)\n",
    "    Accuracy.append(accuracy)\n",
    "    print(model,\", n-gram level TF-IDF Vectors: \",accuracy)\n",
    "\n",
    "    # Classifier on character level TF-IDF vectors\n",
    "    X = tfidf_vect_chars_df.iloc[:,:-1]\n",
    "    y = tfidf_vect_chars_df['intent']\n",
    "    X_train,X_test,y_train,y_test = split_data(X,y)\n",
    "\n",
    "    accuracy = train_model(Classifier,X_train,y_train,X_test,y_test)\n",
    "    Accuracy.append(accuracy)\n",
    "    print(model,\", character level TF-IDF Vectors: \",accuracy)\n",
    "    return Accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes , Count Vectors:  0.8910179640718563\n",
      "NaiveBayes , Word level TF-IDF Vectors:  0.8874251497005988\n",
      "NaiveBayes , n-gram level TF-IDF Vectors:  0.9221556886227545\n",
      "NaiveBayes , character level TF-IDF Vectors:  0.9017964071856287\n"
     ]
    }
   ],
   "source": [
    "# nb stores the accuracy list of naive bayes classifier returned from classifier function.\n",
    "nb = classifier('NaiveBayes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression , Count Vectors:  0.9365269461077844\n",
      "LogisticRegression , Word level TF-IDF Vectors:  0.8778443113772455\n",
      "LogisticRegression , n-gram level TF-IDF Vectors:  0.7916167664670659\n",
      "LogisticRegression , character level TF-IDF Vectors:  0.8826347305389222\n"
     ]
    }
   ],
   "source": [
    "# lr stores the accuracy list of naive bayes classifier returned from classifier function.\n",
    "lr = classifier('LogisticRegression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest , Count Vectors:  0.9089820359281438\n",
      "RandomForest , Word level TF-IDF Vectors:  0.9161676646706587\n",
      "RandomForest , n-gram level TF-IDF Vectors:  0.8467065868263473\n",
      "RandomForest , character level TF-IDF Vectors:  0.9137724550898204\n"
     ]
    }
   ],
   "source": [
    "# rf stores the accuracy list of naive bayes classifier returned from classifier function.\n",
    "rf = classifier('RandomForest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Gradient Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hharshit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb , Count Vectors:  0.9173652694610779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hharshit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb , Word level TF-IDF Vectors:  0.9101796407185628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hharshit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb , n-gram level TF-IDF Vectors:  0.7820359281437126\n",
      "xgb , character level TF-IDF Vectors:  0.9389221556886228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hharshit\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# xgb stores the accuracy list of naive bayes classifier returned from classifier function.\n",
    "xgb = classifier('xgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM , Count Vectors:  0.9520958083832335\n",
      "SVM , Word level TF-IDF Vectors:  0.9532934131736527\n",
      "SVM , n-gram level TF-IDF Vectors:  0.925748502994012\n",
      "SVM , character level TF-IDF Vectors:  0.9520958083832335\n"
     ]
    }
   ],
   "source": [
    "# svm stores the accuracy list of naive bayes classifier returned from classifier function.\n",
    "SVM = classifier('SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of Accuracy across different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbAcc = np.array(nb)\n",
    "logAcc = np.array(lr)\n",
    "rfAcc = np.array(rf)\n",
    "xgbAcc = np.array(xgb)\n",
    "svmAcc = np.array(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_arr = np.vstack([nbAcc,logAcc,rfAcc,xgbAcc,svmAcc]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89101796, 0.93652695, 0.90898204, 0.91736527, 0.95209581],\n",
       "       [0.88742515, 0.87784431, 0.91616766, 0.91017964, 0.95329341],\n",
       "       [0.92215569, 0.79161677, 0.84670659, 0.78203593, 0.9257485 ],\n",
       "       [0.90179641, 0.88263473, 0.91377246, 0.93892216, 0.95209581]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = pd.DataFrame(accuracy_arr,columns = ['NaiveBayes','logisticRegression','RandomForest','XGBoost','SVM'],\n",
    "                      index = ['Count Vectors','Word tf-idf','ngram tf-idf','character tf-idf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaiveBayes</th>\n",
       "      <th>logisticRegression</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Count Vectors</th>\n",
       "      <td>0.891018</td>\n",
       "      <td>0.936527</td>\n",
       "      <td>0.908982</td>\n",
       "      <td>0.917365</td>\n",
       "      <td>0.952096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word tf-idf</th>\n",
       "      <td>0.887425</td>\n",
       "      <td>0.877844</td>\n",
       "      <td>0.916168</td>\n",
       "      <td>0.910180</td>\n",
       "      <td>0.953293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ngram tf-idf</th>\n",
       "      <td>0.922156</td>\n",
       "      <td>0.791617</td>\n",
       "      <td>0.846707</td>\n",
       "      <td>0.782036</td>\n",
       "      <td>0.925749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character tf-idf</th>\n",
       "      <td>0.901796</td>\n",
       "      <td>0.882635</td>\n",
       "      <td>0.913772</td>\n",
       "      <td>0.938922</td>\n",
       "      <td>0.952096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  NaiveBayes  logisticRegression  RandomForest   XGBoost  \\\n",
       "Count Vectors       0.891018            0.936527      0.908982  0.917365   \n",
       "Word tf-idf         0.887425            0.877844      0.916168  0.910180   \n",
       "ngram tf-idf        0.922156            0.791617      0.846707  0.782036   \n",
       "character tf-idf    0.901796            0.882635      0.913772  0.938922   \n",
       "\n",
       "                       SVM  \n",
       "Count Vectors     0.952096  \n",
       "Word tf-idf       0.953293  \n",
       "ngram tf-idf      0.925749  \n",
       "character tf-idf  0.952096  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(data = acc_df)\n",
    "plt.savefig('accuracy.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\hharshit\\AppData\\Local\\Temp\\tmpkldde9z6\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\hharshit\\\\AppData\\\\Local\\\\Temp\\\\tmpkldde9z6', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D41279D390>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\hharshit\\AppData\\Local\\Temp\\tmpkldde9z6\\model.ckpt.\n",
      "INFO:tensorflow:loss = 30.501879, step = 1\n",
      "INFO:tensorflow:global_step/sec: 6.34419\n",
      "INFO:tensorflow:loss = 3.755035, step = 101 (15.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.54296\n",
      "INFO:tensorflow:loss = 0.25813138, step = 201 (11.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.68443\n",
      "INFO:tensorflow:loss = 1.6323699, step = 301 (11.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.6854\n",
      "INFO:tensorflow:loss = 3.6209857, step = 401 (11.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.62387\n",
      "INFO:tensorflow:loss = 0.5427735, step = 501 (11.606 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 600 into C:\\Users\\hharshit\\AppData\\Local\\Temp\\tmpkldde9z6\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.597534.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hharshit\\AppData\\Local\\Temp\\tmpkldde9z6\\model.ckpt-600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X = vect_df.iloc[:,:-1]\n",
    "y = vect_df['intent']\n",
    "X_train,X_test,y_train,y_test = split_data(X,y)\n",
    "\n",
    "X_train.columns = [col.strip() for col in X_train.columns]\n",
    "\n",
    "feat_cols = []\n",
    "for col in X_train.columns:\n",
    "    feat_cols.append(tf.feature_column.numeric_column(col))\n",
    "\n",
    "input_func = tf.estimator.inputs.pandas_input_fn(x = X_train, y=y_train,batch_size=10,num_epochs=5,shuffle=True)\n",
    "classifier = tf.estimator.DNNClassifier(hidden_units=[1024,512,256],n_classes=21,feature_columns=feat_cols)\n",
    "\n",
    "classifier.train(input_fn = input_func, steps=600)\n",
    "\n",
    "pred_fn = tf.estimator.inputs.pandas_input_fn(x=X_test,batch_size=len(X_test),shuffle=False)\n",
    "predictions = list(classifier.predict(input_fn=pred_fn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87        10\n",
      "          1       0.84      0.73      0.78        22\n",
      "          2       0.67      0.86      0.75         7\n",
      "          3       0.83      1.00      0.91         5\n",
      "          4       0.53      0.73      0.62        11\n",
      "          5       0.69      1.00      0.82         9\n",
      "          6       1.00      0.67      0.80         9\n",
      "          7       0.00      0.00      0.00         8\n",
      "          8       0.94      0.92      0.93       113\n",
      "          9       1.00      1.00      1.00        27\n",
      "         10       1.00      1.00      1.00        35\n",
      "         11       0.99      0.95      0.97       153\n",
      "         12       0.90      0.94      0.92        47\n",
      "         13       0.92      0.96      0.94        47\n",
      "         14       0.85      0.79      0.81        14\n",
      "         15       0.97      1.00      0.99        37\n",
      "         16       1.00      1.00      1.00        30\n",
      "         17       0.98      0.93      0.95        55\n",
      "         18       0.87      0.99      0.92        68\n",
      "         19       0.96      0.92      0.94        51\n",
      "         20       0.92      0.94      0.93        77\n",
      "\n",
      "avg / total       0.92      0.93      0.92       835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_preds = []\n",
    "\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['class_ids'][0])\n",
    "\n",
    "print(classification_report(y_test,final_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As it can be seen that neural networks are performing at comparable accuracy to other machine learning models. The reason being less amount of data. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96414343 0.93227092 0.93227092 0.95219124 0.964      0.956\n",
      " 0.952      0.976      0.94       0.924     ]\n",
      "Accuracy score: 0.95 +/- 0.02\n"
     ]
    }
   ],
   "source": [
    "X = vect_df.iloc[:,:-1]\n",
    "y = vect_df['intent']\n",
    "X_train,X_test,y_train,y_test = split_data(X,y)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kfold = KFold(n_splits=10,shuffle=True)\n",
    "acc = np.array([])\n",
    "for train_idx,test_idx in kfold.split(X_train,y_train):\n",
    "    X_train_cv,y_train_cv = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    X_test_cv, y_test_cv = X_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    clf = svm.LinearSVC()\n",
    "    clf.fit(X_train_cv, y_train_cv)\n",
    "    predictions = clf.predict(X_test_cv)\n",
    "    \n",
    "    acc = np.append(acc, accuracy_score(y_test_cv,predictions))\n",
    "print(acc)\n",
    "print(\"Accuracy score: %0.2f +/- %0.2f\" %(acc.mean(),acc.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K-Fold cross validation for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95366795 0.94208494 0.95703125 0.96837945 0.95219124 0.96787149\n",
      " 0.92307692 0.97154472 0.95901639 0.975     ]\n",
      "Accuracy score: 0.96 +/- 0.01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "acc = np.array([])\n",
    "for train_idx,test_idx in skf.split(X_train,y_train):\n",
    "    X_train_cv,y_train_cv = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    X_test_cv, y_test_cv = X_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    clf = svm.LinearSVC()\n",
    "    clf.fit(X_train_cv, y_train_cv)\n",
    "    predictions = clf.predict(X_test_cv)\n",
    "    \n",
    "    acc = np.append(acc, accuracy_score(y_test_cv,predictions))\n",
    "print(acc)\n",
    "print(\"Accuracy score: %0.2f +/- %0.2f\" %(acc.mean(),acc.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As it can be seen from the cross validation scores of both the methods that there are high chances that model is free of bias and variance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model : Serialization and Deserialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaiveBayes</th>\n",
       "      <th>logisticRegression</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Count Vectors</th>\n",
       "      <td>0.891018</td>\n",
       "      <td>0.936527</td>\n",
       "      <td>0.908982</td>\n",
       "      <td>0.917365</td>\n",
       "      <td>0.952096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word tf-idf</th>\n",
       "      <td>0.887425</td>\n",
       "      <td>0.877844</td>\n",
       "      <td>0.916168</td>\n",
       "      <td>0.910180</td>\n",
       "      <td>0.953293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ngram tf-idf</th>\n",
       "      <td>0.922156</td>\n",
       "      <td>0.791617</td>\n",
       "      <td>0.846707</td>\n",
       "      <td>0.782036</td>\n",
       "      <td>0.925749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character tf-idf</th>\n",
       "      <td>0.901796</td>\n",
       "      <td>0.882635</td>\n",
       "      <td>0.913772</td>\n",
       "      <td>0.938922</td>\n",
       "      <td>0.952096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  NaiveBayes  logisticRegression  RandomForest   XGBoost  \\\n",
       "Count Vectors       0.891018            0.936527      0.908982  0.917365   \n",
       "Word tf-idf         0.887425            0.877844      0.916168  0.910180   \n",
       "ngram tf-idf        0.922156            0.791617      0.846707  0.782036   \n",
       "character tf-idf    0.901796            0.882635      0.913772  0.938922   \n",
       "\n",
       "                       SVM  \n",
       "Count Vectors     0.952096  \n",
       "Word tf-idf       0.953293  \n",
       "ngram tf-idf      0.925749  \n",
       "character tf-idf  0.952096  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above dataframe we can see that **SVM** model with count vectors and character tf-idf feature vectors gives us maximum accuracy. So, I will save the **SVM** model with count vectors as feature vector by performing serialization or pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVM_hybrid.pkl']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "from sklearn import svm\n",
    "\n",
    "SVM = svm.LinearSVC()\n",
    "X = vect_df.iloc[:,:-1]\n",
    "y = vect_df['intent']\n",
    "X_train,X_test,y_train,y_test = split_data(X,y)\n",
    "SVM.fit(X_train,y_train)\n",
    "\n",
    "# dumping of SVM model\n",
    "joblib.dump(SVM,'SVM_hybrid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block of code creates a dictionary intent_dict so as to map the integer output of the classifier to actual intent values\n",
    "keys = []\n",
    "values = []\n",
    "for i in tfidf_vect_df['intent'].value_counts().iteritems():\n",
    "    keys.append(i[0])\n",
    "\n",
    "for j in data_df['intent'].value_counts().iteritems():\n",
    "    values.append(j[0])\n",
    "\n",
    "intent_dict = dict((keys[i],values[i]) for i in range(len(keys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{11: 'faq.application_process',\n",
       " 8: 'contact.contact',\n",
       " 20: 'faq.borrow_use',\n",
       " 18: 'faq.biz_simpler',\n",
       " 19: 'faq.borrow_limit',\n",
       " 17: 'faq.biz_new',\n",
       " 13: 'faq.apply_register',\n",
       " 12: 'faq.approval_time',\n",
       " 10: 'faq.address_proof',\n",
       " 15: 'faq.banking_option_missing',\n",
       " 16: 'faq.biz_category_missing',\n",
       " 9: 'faq.aadhaar_missing',\n",
       " 1: 'commonQ.bot',\n",
       " 0: 'commonQ.assist',\n",
       " 4: 'commonQ.name',\n",
       " 14: 'faq.bad_service',\n",
       " 2: 'commonQ.how',\n",
       " 5: 'commonQ.not_giving',\n",
       " 7: 'commonQ.query',\n",
       " 6: 'commonQ.wait',\n",
       " 3: 'commonQ.just_details'}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for predicting values by taking string inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    print('Enter your statement: ')\n",
    "    statement = input()\n",
    "    #tokens = statement.split()\n",
    "    #tokens = [str(TextBlob(word).correct()) for word in tokens]\n",
    "    #statement = \" \".join(tokens)\n",
    "    \n",
    "    vect = CountVectorizer(vocabulary= vect_df.iloc[:,:-1].columns)\n",
    "\n",
    "    x = vect.fit_transform([statement])\n",
    "    \n",
    "    svmClassifier = joblib.load(r'D:\\ML Projects\\intent\\SVM_hybrid.pkl')\n",
    "    pred = svmClassifier.predict(x.toarray())\n",
    "    print(intent_dict[pred[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your statement: \n",
      "kya aap meri madad kar skte hai\n",
      "commonQ.assist\n",
      "Enter your statement: \n",
      "loan k lie kaise apply karu\n",
      "faq.application_process\n",
      "Enter your statement: \n",
      "which type of loan is good for small business\n",
      "faq.biz_simpler\n",
      "Enter your statement: \n",
      "chote business k lie kis tarah ka loan accha hai\n",
      "faq.biz_simpler\n",
      "Enter your statement: \n",
      "kaise ho\n",
      "commonQ.how\n"
     ]
    }
   ],
   "source": [
    "# These are just sample test cases to check the accuracy of model. \n",
    "i=0\n",
    "while i<5:\n",
    "    predict()\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
